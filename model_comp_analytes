######################################################
# Two-Stage Classification with Separate Concentration Models per Analyte
# Using Stratified Splits to Ensure Multiple Classes per Train Set
# Prints accuracy for each model at each step
######################################################

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

############# Configurations ############
seed = 20785161
np.random.seed(seed)

# Two analytes: IPA and EtOH
analyte_values = {
    "IPA": 1,
    "EtOH": 2  
}

# Concentrations mapped to classes
class_values = {
    250: 1,
    350: 2,
    450: 3
}

inv_analyte_values = {v: k for k, v in analyte_values.items()}
inv_class_values = {v: k for k, v in class_values.items()}

############# Load Data ############
data = pd.read_csv("summary_output/summary.csv")

# Filter to only IPA and EtOH
data = data[data["Analyte"].isin(analyte_values.keys())]

data["AnalyteClass"] = data["Analyte"].map(analyte_values)
data["ConcClass"] = data["Conc"].map(class_values)
data['Sample ID'] = data['Filename']

pivoted_data = data.pivot(index="Sample ID", columns="Sensor ID")[["Delta R On", "Delta R Off"]].reset_index()
pivoted_data["AnalyteClass"] = data.groupby("Sample ID")["AnalyteClass"].first().values
pivoted_data["ConcClass"] = data.groupby("Sample ID")["ConcClass"].first().values

pivoted_data = pivoted_data.fillna(0)

############# Analyte Classification ############
X_analyte = pivoted_data.drop(columns=["Sample ID", "ConcClass", "AnalyteClass"])
y_analyte = pivoted_data["AnalyteClass"]

# Stratify by analyte class to ensure both classes appear in train/test
X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(
    X_analyte, y_analyte, test_size=0.3, random_state=seed, stratify=y_analyte
)

scaler_analyte = StandardScaler()
X_train_a_scaled = scaler_analyte.fit_transform(X_train_a)
X_test_a_scaled = scaler_analyte.transform(X_test_a)

analyte_models = {
    "SVC": SVC(class_weight='balanced', kernel='rbf', C=100, gamma='auto', random_state=seed),
    "Random Forest": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=seed),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, random_state=seed)
}

analyte_results = {}
print("\n=== Analyte Classification Results ===")
for model_name, model in analyte_models.items():
    if model_name == "SVC":
        model.fit(X_train_a_scaled, y_train_a)
        y_pred_a = model.predict(X_test_a_scaled)
    else:
        model.fit(X_train_a, y_train_a)
        y_pred_a = model.predict(X_test_a)
    
    acc = accuracy_score(y_test_a, y_pred_a)
    analyte_results[model_name] = {
        "Accuracy": acc,
        "Model": model,
        "Predictions": y_pred_a
    }
    # Print accuracy for each model
    print(f"{model_name} Accuracy: {acc:.2f}")

best_analyte_model_name = max(analyte_results, key=lambda x: analyte_results[x]["Accuracy"])
best_analyte_model = analyte_results[best_analyte_model_name]["Model"]
y_pred_a_final = analyte_results[best_analyte_model_name]["Predictions"]
print(f"Best analyte model: {best_analyte_model_name}, Accuracy: {analyte_results[best_analyte_model_name]['Accuracy']:.2f}")

############# Separate Concentration Classification per Analyte ############
ipa_data = pivoted_data[pivoted_data["AnalyteClass"] == analyte_values["IPA"]]
etoh_data = pivoted_data[pivoted_data["AnalyteClass"] == analyte_values["EtOh"]] if "EtOh" in analyte_values else pivoted_data[pivoted_data["AnalyteClass"] == analyte_values["EtOH"]]

# IPA concentrations
X_ipa = ipa_data.drop(columns=["Sample ID", "ConcClass", "AnalyteClass"])
y_ipa = ipa_data["ConcClass"]
print("\nIPA concentration distribution:")
print(y_ipa.value_counts())

X_train_ipa, X_test_ipa, y_train_ipa, y_test_ipa = train_test_split(
    X_ipa, y_ipa, test_size=0.3, random_state=seed, stratify=y_ipa
)

scaler_ipa = StandardScaler()
X_train_ipa_scaled = scaler_ipa.fit_transform(X_train_ipa)
X_test_ipa_scaled = scaler_ipa.transform(X_test_ipa)

ipa_models = {
    "SVC": SVC(class_weight='balanced', kernel='rbf', C=100, gamma='auto', random_state=seed),
    "Random Forest": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=seed),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, random_state=seed)
}

ipa_results = {}
print("\n=== IPA Concentration Classification Results ===")
for model_name, model in ipa_models.items():
    if model_name == "SVC":
        model.fit(X_train_ipa_scaled, y_train_ipa)
        y_pred_ipa = model.predict(X_test_ipa_scaled)
    else:
        model.fit(X_train_ipa, y_train_ipa)
        y_pred_ipa = model.predict(X_test_ipa)
    
    acc = accuracy_score(y_test_ipa, y_pred_ipa)
    ipa_results[model_name] = {
        "Accuracy": acc,
        "Model": model,
        "Predictions": y_pred_ipa
    }
    # Print accuracy for each model
    print(f"{model_name} Accuracy: {acc:.2f}")

best_ipa_model_name = max(ipa_results, key=lambda x: ipa_results[x]["Accuracy"])
best_ipa_model = ipa_results[best_ipa_model_name]["Model"]
y_pred_ipa_final = ipa_results[best_ipa_model_name]["Predictions"]
print(f"Best IPA concentration model: {best_ipa_model_name}, Accuracy: {ipa_results[best_ipa_model_name]['Accuracy']:.2f}")

# EtOH concentrations
X_etoh = etoh_data.drop(columns=["Sample ID", "ConcClass", "AnalyteClass"])
y_etoh = etoh_data["ConcClass"]
print("\nEtOH concentration distribution:")
print(y_etoh.value_counts())

X_train_etoh, X_test_etoh, y_train_etoh, y_test_etoh = train_test_split(
    X_etoh, y_etoh, test_size=0.3, random_state=seed, stratify=y_etoh
)

scaler_etoh = StandardScaler()
X_train_etoh_scaled = scaler_etoh.fit_transform(X_train_etoh)
X_test_etoh_scaled = scaler_etoh.transform(X_test_etoh)

etoh_models = {
    "SVC": SVC(class_weight='balanced', kernel='rbf', C=100, gamma='auto', random_state=seed),
    "Random Forest": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=seed),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, random_state=seed)
}

etoh_results = {}
print("\n=== EtOH Concentration Classification Results ===")
for model_name, model in etoh_models.items():
    if model_name == "SVC":
        model.fit(X_train_etoh_scaled, y_train_etoh)
        y_pred_etoh = model.predict(X_test_etoh_scaled)
    else:
        model.fit(X_train_etoh, y_train_etoh)
        y_pred_etoh = model.predict(X_test_etoh)
    
    acc = accuracy_score(y_test_etoh, y_pred_etoh)
    etoh_results[model_name] = {
        "Accuracy": acc,
        "Model": model,
        "Predictions": y_pred_etoh
    }
    # Print accuracy for each model
    print(f"{model_name} Accuracy: {acc:.2f}")

best_etoh_model_name = max(etoh_results, key=lambda x: etoh_results[x]["Accuracy"])
best_etoh_model = etoh_results[best_etoh_model_name]["Model"]
y_pred_etoh_final = etoh_results[best_etoh_model_name]["Predictions"]
print(f"Best EtOH concentration model: {best_etoh_model_name}, Accuracy: {etoh_results[best_etoh_model_name]['Accuracy']:.2f}")

############# Combine Predictions for the Main Test Set ############
# Use the best analyte model to predict analyte on X_test_a.
if best_analyte_model_name == "SVC":
    y_pred_a_test = best_analyte_model.predict(X_test_a_scaled)
else:
    y_pred_a_test = best_analyte_model.predict(X_test_a)

# True concentrations for the analyte test set
y_test_conc = pivoted_data.loc[X_test_a.index, "ConcClass"]

# Predict concentrations using the appropriate model based on predicted analyte
y_pred_c_test = []
for idx, pred_a in zip(X_test_a.index, y_pred_a_test):
    row = X_test_a.loc[idx].values.reshape(1, -1)
    if pred_a == analyte_values["IPA"]:
        # Use IPA model
        if best_ipa_model_name == "SVC":
            row_scaled = scaler_ipa.transform(row)
            pred_c = best_ipa_model.predict(row_scaled)[0]
        else:
            pred_c = best_ipa_model.predict(row)[0]
    else:
        # Use EtOH model
        if best_etoh_model_name == "SVC":
            row_scaled = scaler_etoh.transform(row)
            pred_c = best_etoh_model.predict(row_scaled)[0]
        else:
            pred_c = best_etoh_model.predict(row)[0]
    y_pred_c_test.append(pred_c)

y_pred_c_test = np.array(y_pred_c_test)

# Combine analyte & concentration into labels
y_true_combined = [
    f"{inv_analyte_values[a]}_{c}"
    for a, c in zip(y_test_a, y_test_conc)
]

y_pred_combined = [
    f"{inv_analyte_values[a]}_{c}"
    for a, c in zip(y_pred_a_test, y_pred_c_test)
]

unique_labels = np.unique(y_true_combined)
cm_combined = confusion_matrix(y_true_combined, y_pred_combined, labels=unique_labels)
report_combined = classification_report(y_true_combined, y_pred_combined, labels=unique_labels)

print("\n=== Combined Analyte & Concentration Classification ===")
print("Classification Report:")
print(report_combined)
print("Confusion Matrix:")
print(cm_combined)

# Plot combined confusion matrix
fig, ax = plt.subplots(figsize=(8, 8))
cax = ax.matshow(cm_combined, cmap='viridis')
ax.set_title("Combined Confusion Matrix (Analyte & Concentration)")
ax.set_xlabel("Predicted")
ax.set_ylabel("True")
plt.xticks(range(len(unique_labels)), unique_labels, rotation=90)
plt.yticks(range(len(unique_labels)), unique_labels)

for (row, col), value in np.ndenumerate(cm_combined):
    ax.text(col, row, f"{value}", ha='center', va='center', color="white")

fig.colorbar(cax)
plt.tight_layout()
plt.show()
